# Getting Started with Data Pipelines for ETL

Data pipelines are everywhere! More than ever, data practitioners find themselves needing to extract, transform, and load data to power the work they do. During this code-along, I'll walk through the basics of building a data pipeline using Python, `pandas`, and `sqlite`. 

Throughout the tutorial, I'll be using the "Google Play Store Apps" dataset, available in DataCamp Workspaces. The two datasets we'll be using is made available as `.csv` files, and will be transformed throughout the code-along before being loaded into a `sqlite` database.
